# ğŸ¯ Clean Slate: DER++ to Causal-DER Roadmap

**Date:** October 20, 2025  
**Status:** âœ… Codebase cleaned, ready for rewrite  
**Strategy:** Build incrementally on proven DER++ baseline

---

## ğŸ“Š Current Status

### Cleaned Up âœ…
- âŒ Removed 25+ experimental training modules
- âŒ Removed duplicate data/config directories  
- âŒ Removed failed experiment documentation
- âŒ Removed old test scripts and validation code
- âœ… Backed up everything to: `cleanup_backup_20251020_113904/`

### Preserved Core âœ…
```
Symbio AI/
â”œâ”€â”€ mammoth/                    # âœ… Official Mammoth framework (untouched)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ derpp.py           # âœ… Reference DER++ (56% Task-IL, WORKING)
â”‚   â”‚   â””â”€â”€ causal_der.py      # âš ï¸  Will update to use new engine
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ __init__.py            # âœ… Package init
â”‚   â””â”€â”€ causal_der.py          # âš ï¸  Will rewrite as causal_der_v2.py
â”œâ”€â”€ validation/                # âœ… Validation framework
â”œâ”€â”€ requirements.txt           # âœ… Dependencies
â”œâ”€â”€ README.md                  # âœ… Project docs
â””â”€â”€ .vscode/                   # âœ… IDE settings
```

---

## ğŸš€ Implementation Plan

### Phase 1: Clean DER++ Baseline (Week 1)
**Goal:** Match Mammoth's DER++ performance exactly (56% Task-IL on seq-cifar100)

**Tasks:**
1. âœ… Clean up codebase (DONE)
2. ğŸ“ Create `training/causal_der_v2.py`:
   - Copy exact loss from `mammoth/models/derpp.py` (3 lines)
   - Copy exact buffer implementation
   - Simple, clean, no sanitization
   - No causal features yet
3. ğŸ§ª Test and verify:
   - Run: `python mammoth/utils/main.py --model causal-der ...`
   - Expected: ~56% Task-IL (matching DER++)
   - If matched: âœ… BASELINE ESTABLISHED

**Success Criteria:**
- [ ] causal_der_v2.py matches derpp.py performance (Â±2%)
- [ ] No NaN issues
- [ ] Buffer fills to 500/500
- [ ] Clean, readable code (<500 lines)

---

### Phase 2: Causal Importance Scoring (Week 2)
**Goal:** Add lightweight causal importance, measure impact

**What to Add:**
```python
# Compute importance during store()
importance = compute_simple_importance(
    prediction_confidence,  # How confident is the model?
    loss_value,            # How hard is this sample?
    task_novelty           # Is this a new pattern?
)
```

**Ablation Study:**
- Baseline: uniform importance = 1.0
- Test: causal importance weighting
- Measure: Does Task-IL improve? By how much?

**Expected Gain:** +1-2% Task-IL (modest improvement)

---

### Phase 3: Causal Sampling (Week 3)
**Goal:** Sample buffer based on causal importance

**What to Add:**
```python
# During buffer.sample()
if use_causal_sampling:
    probs = importances / importances.sum()
    indices = np.random.choice(len(buffer), size=batch_size, p=probs)
else:
    indices = np.random.choice(len(buffer), size=batch_size)  # uniform
```

**Ablation Study:**
- Test A: Uniform sampling (baseline)
- Test B: Importance-weighted sampling
- Test C: Temperature-scaled sampling (T=2.0)

**Expected Gain:** +2-3% Task-IL

---

### Phase 4: Causal Graph Learning (Week 4)
**Goal:** Discover task dependencies, bias replay toward helpful tasks

**What to Add:**
```python
# After each task
def learn_task_graph():
    # Measure: Does replaying Task i help with Task j?
    # Method: Simple correlation analysis
    # Output: NxN adjacency matrix (task dependencies)
    
# During sampling
def bias_toward_helpful_tasks(current_task, causal_graph):
    # Give higher weight to samples from causally-related tasks
    task_weights = causal_graph[current_task]
    return task_weights
```

**Ablation Study:**
- Test A: No task bias (baseline)
- Test B: Causal graph bias
- Measure: Does it reduce forgetting?

**Expected Gain:** +3-5% Task-IL

---

### Phase 5: Advanced Features (Week 5+)
**Only add if Phase 1-4 show consistent improvements**

Candidates:
- MIR sampling (Maximal Interfered Retrieval)
- Counterfactual augmentation
- Enhanced IRM (Invariant Risk Minimization)

**Each feature:**
1. Implement in isolation
2. Run ablation study
3. Keep only if improves performance
4. Document results for paper

---

## ğŸ“ Paper Outline

### Title
"Causal-DER: Causal Reasoning for Dark Experience Replay in Continual Learning"

### Key Claims (Build Evidence Incrementally)
1. **Causal Importance** improves sample selection (Phase 2 results)
2. **Causal Sampling** reduces catastrophic forgetting (Phase 3 results)
3. **Task Graph Learning** discovers curriculum structure (Phase 4 results)
4. **Ablation Studies** show each component contributes (All phases)

### Experimental Setup
- Baseline: DER++ (56% Task-IL on seq-cifar100)
- Causal-DER: Incremental improvements documented
- Fair comparison: Same hyperparameters, same compute
- Multiple seeds: 3-5 runs per configuration

---

## ğŸ”§ Technical Principles

### Code Quality
- âœ… Simple and readable (prefer clarity over cleverness)
- âœ… Well-documented (explain WHY, not just WHAT)
- âœ… Modular (each causal feature is a separate function)
- âœ… Testable (can disable any feature with a flag)

### Experimental Rigor
- âœ… One change at a time
- âœ… Proper ablation studies
- âœ… Fair baselines (same hyperparameters)
- âœ… Statistical significance (multiple seeds)

### Incremental Development
- âœ… Phase 1 must work before Phase 2
- âœ… Each phase: implement â†’ test â†’ measure â†’ document
- âœ… Drop features that don't help
- âœ… Keep only what improves performance

---

## ğŸ“Š Success Metrics

### Phase 1 (Baseline)
- [x] Codebase cleaned
- [ ] DER++ baseline reproduced (56% Task-IL)
- [ ] Code is clean (<500 lines)
- [ ] No NaN issues

### Phase 2 (Causal Importance)
- [ ] Importance scoring implemented
- [ ] Ablation study completed
- [ ] Results documented
- [ ] Gain: +1-2% Task-IL (if any)

### Phase 3 (Causal Sampling)
- [ ] Sampling bias implemented
- [ ] Ablation study completed
- [ ] Results documented
- [ ] Gain: +2-3% Task-IL (cumulative)

### Phase 4 (Task Graph)
- [ ] Graph learning implemented
- [ ] Ablation study completed
- [ ] Results documented
- [ ] Gain: +3-5% Task-IL (cumulative)

### Final Target
- [ ] **Causal-DER: 60-65% Task-IL** (vs DER++ baseline 56%)
- [ ] **All ablations documented**
- [ ] **Paper draft ready**
- [ ] **Code ready for release**

---

## ğŸ¯ Next Immediate Steps

1. **Create `training/causal_der_v2.py`**
   - Copy structure from `mammoth/models/derpp.py`
   - Implement clean DER++ engine
   - Add hooks for future causal features (commented out)

2. **Update `mammoth/models/causal_der.py`**
   - Import new CausalDEREngine from causal_der_v2
   - Keep same CLI arguments
   - Keep same observe() interface

3. **Test Baseline**
   - Run: `python mammoth/utils/main.py --model causal-der --dataset seq-cifar100 ...`
   - Expected: 56% Task-IL (Â± 2%)
   - If not matched: debug until it matches

4. **Document Baseline Results**
   - Create `BASELINE_RESULTS.md`
   - Record exact hyperparameters
   - Record performance across 3 seeds
   - This is our reference point

---

## ğŸ’¡ Key Insights from Failed Attempt

**What Went Wrong:**
- âŒ Started with complex causal features before baseline worked
- âŒ Too much sanitization (torch.nan_to_num killed gradients)
- âŒ Causal code ran even when features "disabled"
- âŒ Lost track of what was causing issues
- âŒ Couldn't tell if bugs were in DER++ or causal parts

**What We Learned:**
- âœ… Always start with working baseline
- âœ… Add complexity incrementally
- âœ… One feature at a time
- âœ… Measure impact of each feature
- âœ… Keep code simple and readable

**Why This Approach Will Succeed:**
- âœ… We have a working DER++ reference (56%)
- âœ… We can copy exact implementation
- âœ… We can verify baseline before adding features
- âœ… We can measure exact contribution of each feature
- âœ… We can build publication-quality evidence

---

## ğŸ“š References

**Mammoth DER++:**
- File: `mammoth/models/derpp.py` (60 lines, works perfectly)
- Performance: 56.06% Task-IL on seq-cifar100 (verified)
- Hyperparameters: alpha=0.1, beta=0.5, lr=0.03, momentum=0

**DER++ Paper:**
- Buzzega et al. (2020) "Dark Experience for General Continual Learning"
- Simple: CE(current) + Î±Â·MSE(replay_logits) + Î²Â·CE(replay_labels)
- No temperature scaling, no sanitization, just works

**Our Innovation:**
- Add causal reasoning on top of proven baseline
- Measure exact contribution of each component
- Build evidence for publication claims

---

**Status:** Ready to begin Phase 1 (Clean DER++ Baseline)  
**Confidence:** HIGH (we have working reference implementation)  
**Timeline:** 4-5 weeks to complete all phases  
**Goal:** Publishable results with clean ablation studies
