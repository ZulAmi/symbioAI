# ‚úÖ RunPod Setup Verification Guide

**Run this checklist BEFORE starting benchmarks on RunPod!**

---

## üöÄ **QUICK VERIFICATION (1 minute)**

```bash
# Run automatic verification script:
python3 verify_runpod_setup.py
```

**Expected output:**

```
üéâ ALL CHECKS PASSED!
‚úÖ Your RunPod environment is ready for benchmarks!
```

If you see this, **skip to step 5** and start benchmarks!

---

## üîß **MANUAL VERIFICATION** (if auto-check fails)

### **Step 1: Check Python** ‚è±Ô∏è 10 seconds

```bash
python3 --version
```

**Expected:** Python 3.8 or higher  
**‚úÖ Good:** `Python 3.10.12` or similar  
**‚ùå Bad:** `Python 2.7` or `Python 3.6`

**Fix if needed:**

```bash
# RunPod usually has Python 3.10+ pre-installed
# If not, contact RunPod support
```

---

### **Step 2: Check GPU** ‚è±Ô∏è 10 seconds

```bash
nvidia-smi
```

**Expected output:**

```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.xx       Driver Version: 525.xx       CUDA Version: 12.x   |
|-------------------------------+----------------------+----------------------+
|   0  NVIDIA RTX 4090    On   | 00000000:01:00.0 Off |                  N/A |
```

**‚úÖ Good signs:**

- You see GPU name (RTX 4090, A10, A100, etc.)
- GPU memory shown (24GB, 40GB, etc.)
- CUDA version shown

**‚ùå Bad signs:**

- "command not found"
- No GPU listed
- Error messages

**Fix if needed:**

```bash
# This should not happen on RunPod
# If it does, your pod didn't start correctly
# Stop and restart the pod
```

---

### **Step 3: Check PyTorch + GPU** ‚è±Ô∏è 20 seconds

```bash
python3 -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\"}')"
```

**Expected output:**

```
PyTorch: 2.1.2
CUDA available: True
GPU: NVIDIA GeForce RTX 4090
```

**‚úÖ Good:** All three lines show correct info  
**‚ùå Bad:** `CUDA available: False`

**Fix if needed:**

```bash
# If PyTorch not installed:
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# If CUDA not available, restart pod
```

---

### **Step 4: Check Dependencies** ‚è±Ô∏è 30 seconds

```bash
python3 -c "import numpy, pandas, matplotlib, sklearn; print('‚úÖ All core packages installed')"
```

**Expected output:**

```
‚úÖ All core packages installed
```

**‚ùå If you see import errors:**

```bash
pip install -r requirements.txt
```

---

### **Step 5: Test GPU Computation** ‚è±Ô∏è 10 seconds

```bash
python3 -c "import torch; x=torch.randn(1000,1000).cuda(); y=torch.randn(1000,1000).cuda(); z=torch.mm(x,y); print('‚úÖ GPU computation works!')"
```

**Expected output:**

```
‚úÖ GPU computation works!
```

**‚úÖ This confirms GPU is working!**

---

### **Step 6: Check Disk Space** ‚è±Ô∏è 5 seconds

```bash
df -h /workspace
```

**Expected output:**

```
Filesystem      Size  Used Avail Use% Mounted on
...            50G   5.0G   45G  10% /workspace
```

**‚úÖ Good:** At least 10GB free  
**‚ö†Ô∏è Warning:** Less than 10GB free (might run out during benchmarks)

---

### **Step 7: Check Files** ‚è±Ô∏è 10 seconds

```bash
ls -la | grep -E "(run_benchmarks|test_core|requirements)"
```

**Expected output:**

```
-rw-r--r--  1 root  run_benchmarks.py
-rw-r--r--  1 root  test_core_benchmark.py
-rw-r--r--  1 root  requirements.txt
```

**‚úÖ Good:** All three files present  
**‚ùå Bad:** Files missing (you're in wrong directory)

**Fix if needed:**

```bash
# Navigate to correct directory
cd /workspace/symbioAI
# or
cd ~/symbioAI
```

---

## üéØ **FINAL VERIFICATION TEST**

### **Run Core Benchmark Test** ‚è±Ô∏è 1 minute

```bash
python3 test_core_benchmark.py
```

**Expected output:**

```
‚úÖ‚úÖ‚úÖ CORE BENCHMARK LOOP WORKS!
‚úÖ PyTorch training/eval works correctly
```

**If you see this = READY TO GO!** ‚úÖ

---

## ‚úÖ **VERIFICATION CHECKLIST**

**Before starting full benchmarks, confirm:**

- [x] Python 3.8+ installed
- [x] GPU detected by nvidia-smi
- [x] PyTorch installed and sees GPU
- [x] CUDA available in PyTorch
- [x] Core packages installed
- [x] GPU computation works
- [x] At least 10GB disk space
- [x] Project files present
- [x] test_core_benchmark.py passes

**All checked? You're ready!** üöÄ

---

## üöÄ **START BENCHMARKS**

```bash
# Create screen session (so it runs if you disconnect)
screen -S benchmarks

# Start benchmarks
python3 run_benchmarks.py --mode full

# Detach from screen: Ctrl+A, then D
```

**Monitor progress:**

```bash
# Reattach to screen
screen -r benchmarks

# Check GPU usage
nvidia-smi
```

---

## üÜò **TROUBLESHOOTING**

### **Issue: "No module named 'torch'"**

```bash
pip install torch torchvision
```

### **Issue: "CUDA not available"**

```bash
# Restart your RunPod instance
# Or select PyTorch template when launching
```

### **Issue: "Permission denied"**

```bash
chmod +x run_benchmarks.py
```

### **Issue: "Out of disk space"**

```bash
# Clean up
rm -rf ~/.cache/pip
rm -rf data/*.tar.gz

# Or increase container disk when launching pod
```

### **Issue: "GPU out of memory"**

```bash
# Reduce batch size in run_benchmarks.py
# Or use smaller model
```

---

## üìä **EXPECTED RESOURCE USAGE**

For full benchmarks (16 hours):

| Resource       | Usage     | Your GPU   |
| -------------- | --------- | ---------- |
| **GPU Memory** | 6-8 GB    | 24 GB ‚úÖ   |
| **Disk Space** | 5-10 GB   | 50 GB ‚úÖ   |
| **RAM**        | 8-16 GB   | 32 GB ‚úÖ   |
| **CPU**        | 4-8 cores | 8 cores ‚úÖ |

**Your RunPod pod is MORE than enough!** üí™

---

## ‚úÖ **QUICK REFERENCE**

```bash
# Verify setup
python3 verify_runpod_setup.py

# Test core functionality
python3 test_core_benchmark.py

# Start benchmarks
screen -S benchmarks
python3 run_benchmarks.py --mode full

# Detach: Ctrl+A, D

# Check status later
screen -r benchmarks
nvidia-smi

# Stop GPU when done
# (In RunPod dashboard: click "Stop")
```

---

**All set? Let's go!** üöÄ
